{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f4dcc484-fdad-4893-94bd-9664d0745a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: groq in c:\\users\\pavithran\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\pavithran\\appdata\\roaming\\python\\python312\\site-packages (from groq) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\pavithran\\appdata\\roaming\\python\\python312\\site-packages (from groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\pavithran\\appdata\\roaming\\python\\python312\\site-packages (from groq) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\pavithran\\appdata\\roaming\\python\\python312\\site-packages (from groq) (2.7.1)\n",
      "Requirement already satisfied: sniffio in c:\\users\\pavithran\\appdata\\roaming\\python\\python312\\site-packages (from groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\pavithran\\appdata\\roaming\\python\\python312\\site-packages (from groq) (4.10.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\pavithran\\appdata\\roaming\\python\\python312\\site-packages (from anyio<5,>=3.5.0->groq) (2.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\pavithran\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->groq) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\pavithran\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->groq) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\pavithran\\appdata\\roaming\\python\\python312\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\pavithran\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in c:\\users\\pavithran\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3,>=1.9.0->groq) (2.18.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "39cea64b-14c3-4c80-8c42-812509bb3408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['GROQ_API_KEY']=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de469e34-ee68-4f15-9038-2c96dee399ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast language models have revolutionized the field of Natural Language Processing (NLP) and have numerous applications in various industries. The importance of fast language models can be summarized as follows:\n",
      "\n",
      "1. **Efficient Processing**: Fast language models can process large amounts of text data quickly, enabling applications to respond rapidly to user input. This is particularly crucial in real-time applications, such as chatbots, virtual assistants, and language translation services.\n",
      "2. **Scalability**: Fast language models can handle large-scale datasets and process them efficiently, making them suitable for industrial-scale applications, such as text classification, sentiment analysis, and information retrieval.\n",
      "3. **Low Latency**: Fast language models reduce the latency between user input and system response, providing a more interactive and engaging user experience. This is particularly important in applications like language translation, where timely responses are critical.\n",
      "4. **Real-time Insights**: Fast language models can provide real-time insights and analytics on large volumes of text data, enabling businesses to respond swiftly to changing market conditions, customer sentiments, and trends.\n",
      "5. **Improved Accuracy**: Fast language models can process data in parallel, leveraging the power of distributed computing, which leads to improved accuracy and better decision-making.\n",
      "6. **Cost-Effective**: Fast language models reduce the computational resources required to process language data, making them a cost-effective solution for businesses and organizations.\n",
      "7. **Enhanced User Experience**: Fast language models enable the development of more sophisticated language-based interfaces, such as voice assistants, chatbots, and conversational AI, which can understand and respond to users more effectively.\n",
      "8. **Competitive Advantage**: Organizations that leverage fast language models can gain a competitive advantage by processing and analyzing large amounts of text data quickly, enabling them to respond faster to market changes and customer needs.\n",
      "9. **Research and Development**: Fast language models accelerate research and development in NLP, enabling scientists and engineers to experiment with new ideas, test hypotheses, and iterate on models more quickly.\n",
      "10. **Societal Impact**: Fast language models have the potential to positively impact various aspects of society, such as healthcare, education, and accessibility, by enabling the development of applications that can process and analyze large amounts of text data quickly and accurately.\n",
      "\n",
      "Some examples of applications that benefit from fast language models include:\n",
      "\n",
      "1. Virtual assistants, like Siri, Alexa, and Google Assistant, which rely on fast language models to understand and respond to user queries.\n",
      "2. Language translation services, like Google Translate, which use fast language models to translate text and speech in real-time.\n",
      "3. Chatbots and conversational AI, which employ fast language models to engage with customers and provide customer support.\n",
      "4. Sentiment analysis and text analytics tools, which rely on fast language models to process and analyze large volumes of text data.\n",
      "5. Language-based interfaces for individuals with disabilities, which use fast language models to enable communication and access to information.\n",
      "\n",
      "In summary, fast language models have far-reaching implications for various industries and applications, enabling efficient processing, scalability, low latency, and improved accuracy, among other benefits.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from groq import Groq\n",
    "\n",
    "client = Groq(\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the importance of fast language models\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama3-70b-8192\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ed443e6-9bff-43b1-a1e0-28008747d8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, client: Groq, system: str = \"\") -> None:\n",
    "        self.client = client\n",
    "        self.system = system\n",
    "        self.messages: list = []\n",
    "        if self.system:\n",
    "            self.messages.append({\"role\": \"system\", \"content\": system})\n",
    "\n",
    "    def __call__(self, message=\"\"):\n",
    "        if message:\n",
    "            self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "        result = self.execute()\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": result})\n",
    "        return result\n",
    "\n",
    "    def execute(self):\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"llama3-70b-8192\", messages=self.messages\n",
    "        )\n",
    "        return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "178c3af9-b2f5-4a9a-b93e-f683c5217c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You run in a loop of Thought, Action, PAUSE, Observation.\n",
    "At the end of the loop you output an Answer\n",
    "Use Thought to describe your thoughts about the question you have been asked.\n",
    "Use Action to run one of the actions available to you - then return PAUSE.\n",
    "Observation will be the result of running those actions.\n",
    "\n",
    "Your available actions are:\n",
    "\n",
    "calculate:\n",
    "e.g. calculate: 4 * 7 / 3\n",
    "Runs a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary\n",
    "\n",
    "get_planet_mass:\n",
    "e.g. get_planet_mass: Earth\n",
    "returns weight of the planet in kg\n",
    "\n",
    "Example session:\n",
    "\n",
    "Question: What is the mass of Earth times 2?\n",
    "Thought: I need to find the mass of Earth\n",
    "Action: get_planet_mass: Earth\n",
    "PAUSE \n",
    "\n",
    "You will be called again with this:\n",
    "\n",
    "Observation: 5.972e24\n",
    "\n",
    "Thought: I need to multiply this by 2\n",
    "Action: calculate: 5.972e24 * 2\n",
    "PAUSE\n",
    "\n",
    "You will be called again with this: \n",
    "\n",
    "Observation: 1,1944×10e25\n",
    "\n",
    "If you have the answer, output it as the Answer.\n",
    "\n",
    "Answer: The mass of Earth times 2 is 1,1944×10e25.\n",
    "\n",
    "Now it's your turn:\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "def calculate(operation: str) -> float:\n",
    "    return eval(operation)\n",
    "\n",
    "\n",
    "def get_planet_mass(planet) -> float:\n",
    "    match planet.lower():\n",
    "        case \"earth\":\n",
    "            return 5.972e24\n",
    "        case \"jupiter\":\n",
    "            return 1.898e27\n",
    "        case \"mars\":\n",
    "            return 6.39e23\n",
    "        case \"mercury\":\n",
    "            return 3.285e23\n",
    "        case \"neptune\":\n",
    "            return 1.024e26\n",
    "        case \"saturn\":\n",
    "            return 5.683e26\n",
    "        case \"uranus\":\n",
    "            return 8.681e25\n",
    "        case \"venus\":\n",
    "            return 4.867e24\n",
    "        case _:\n",
    "            return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e85e7c5e-41dc-4f13-97d8-6df76493fded",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent=Agent(client=client, system=system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "304dff2f-f69d-42f4-a0d2-bad1d799a871",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: I need to find the mass of all the planets.\n",
      "\n",
      "Action: get_planet_mass: Mercury\n",
      "PAUSE\n",
      "Observation: 3.285e+23\n",
      "Thought: I've got the mass of Mercury, now I need to get the mass of the other planets and add them up.\n",
      "\n",
      "Action: get_planet_mass: Mars\n",
      "PAUSE\n",
      "Observation: 6.39e+23\n",
      "Thought: Okay, I have the mass of Mercury and Mars, now I need to get the mass of the other planets and add them up.\n",
      "\n",
      "Action: get_planet_mass: Venus\n",
      "PAUSE\n",
      "Observation: 4.867e+24\n",
      "Thought: I've got the mass of Mercury, Mars, and Venus, now I need to get the mass of the other planets and add them up.\n",
      "\n",
      "Action: get_planet_mass: Earth\n",
      "PAUSE\n",
      "Observation: 5.972e+24\n",
      "Thought: I've got the mass of Mercury, Mars, Venus, and Earth, now I need to get the mass of the other planets and add them up.\n",
      "\n",
      "Action: get_planet_mass: Neptune\n",
      "PAUSE\n",
      "Observation: 1.024e+26\n",
      "Thought: I've got the mass of Mercury, Mars, Venus, Earth, and Neptune, now I need to get the mass of the other planets and add them up.\n",
      "\n",
      "Action: get_planet_mass: Uranus\n",
      "PAUSE\n",
      "Observation: 8.681e+25\n",
      "Thought: I've got the mass of Mercury, Mars, Venus, Earth, Neptune, and Uranus, now I need to get the mass of Jupiter and Saturn, and then add them all up.\n",
      "\n",
      "Action: get_planet_mass: Saturn\n",
      "PAUSE\n",
      "Observation: 5.683e+26\n",
      "Thought: I've got the mass of Mercury, Mars, Venus, Earth, Neptune, Uranus, and Saturn, now I need to get the mass of Jupiter and then add them all up.\n",
      "\n",
      "Action: get_planet_mass: Jupiter\n",
      "PAUSE\n",
      "Observation: 1.898e+27\n",
      "Thought: I've got the mass of all the planets, now I just need to add them up.\n",
      "\n",
      "Action: calculate: 3.285e+23 + 6.39e+23 + 4.867e+24 + 5.972e+24 + 1.024e+26 + 8.681e+25 + 5.683e+26 + 1.898e+27\n",
      "PAUSE\n",
      "Observation: 2.6673165000000003e+27\n",
      "Thought: I've got the sum of the masses of all the planets!\n",
      "\n",
      "Answer: The sum of the mass of all the planets is 2.6673165000000003e+27.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def loop(max_iterations=30, query: str = \"\"):\n",
    "\n",
    "    agent = Agent(client=client, system=system_prompt)\n",
    "\n",
    "    tools = [\"calculate\", \"get_planet_mass\"]\n",
    "\n",
    "    next_prompt = query\n",
    "\n",
    "    i = 0\n",
    "  \n",
    "    while i < max_iterations:\n",
    "        i += 1\n",
    "        result = agent(next_prompt)\n",
    "        print(result)\n",
    "\n",
    "        if \"PAUSE\" in result and \"Action\" in result:\n",
    "            action = re.findall(r\"Action: ([a-z_]+): (.+)\", result, re.IGNORECASE)\n",
    "            chosen_tool = action[0][0]\n",
    "            arg = action[0][1]\n",
    "\n",
    "            if chosen_tool in tools:\n",
    "                result_tool = eval(f\"{chosen_tool}('{arg}')\")\n",
    "                next_prompt = f\"Observation: {result_tool}\"\n",
    "\n",
    "            else:\n",
    "                next_prompt = \"Observation: Tool not found\"\n",
    "\n",
    "            print(next_prompt)\n",
    "            continue\n",
    "\n",
    "        if \"Answer\" in result:\n",
    "            break\n",
    "\n",
    "\n",
    "loop(query=\"What is the sum of mass of all the planets?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa57eea8-f233-4a90-aaf3-e971d70f8289",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
